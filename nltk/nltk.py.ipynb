{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2daa223f",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf858c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3428499",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"/Users/kexingui/etudes/TAL/PPE/nuage/dumps-textang-anglais.txt\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea6dcc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mt/d148h58s6ts989cfbq0vfyth0000gn/T/ipykernel_17712/3490408283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542205bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "# word_tokenize accepts\n",
    "# a string as an input, not a file.\n",
    "stop_words = open('stopwords-spanish.txt')\n",
    "file1 = open(\"dumps-text-espagnol.txt\")\n",
    " \n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "words = line.split()\n",
    "for r in words:\n",
    "    if not r in stop_words:\n",
    "        appendFile = open('mondico_cut_esp.txt','a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f6896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9259ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################\n",
    "##ici est un test\n",
    "#j'ai essayé le stopword spanish dans nitk, mais il n'est pas efficace, \n",
    "#donc j'utilise mon propre stop word liste. \n",
    "\n",
    "\n",
    "############################\n",
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "# word_tokenize accepts\n",
    "# a string as an input, not a file.\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "file1 = open(\"contextes-espagnol.txt\")\n",
    " \n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "words = line.split()\n",
    "for r in words:\n",
    "    if not r in stop_words:\n",
    "        appendFile = open('context_nltk_espa.txt','a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356146a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "##ici est un test\n",
    "#j'ai essayé le stopword french dans nitk, mais il n'est pas efficace, \n",
    "#donc j'utilise mon propre stop word liste-fr. \n",
    "\n",
    "\n",
    "############################\n",
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "# word_tokenize accepts\n",
    "# a string as an input, not a file.\n",
    "stop_words = set(stopwords.words('french'))\n",
    "file1 = open(\"/Users/kexingui/etudes/文档处理/fr/contextes-français.txt\")\n",
    " \n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "words = line.split()\n",
    "for r in words:\n",
    "    if not r in stop_words:\n",
    "        appendFile = open('/Users/kexingui/etudes/文档处理/fr/nltk_français.txt','a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7e5dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723\n",
      "{'ci', 'ils', 'chère', 'possibles', 'necessairement', 'quant', 'eus', 'lui-même', 'car', 'soit', 'force', 'restant', 'tic', 'dessus', 'hep', 'toi-même', 'ou', 'devers', 'ceux-là', 'sien', 'douzième', 'rendre', 'miennes', 'elle', 'et', 'à', 't', 'quels', 'anterieur', 'floc', 'seulement', 'serai', 'ailleurs', 'eurent', ')', 'soi', 'egale', 'eussent', 'moindres', 'va', 'nos', 'ayants', 'aussi', 'cent', 'dehors', 'moi', 'zut', 'unique', 'specifique', 'eussiez', 'ouste', 'envers', 'été', 'desquelles', 'fi', 'même', 'enfin', 'eues', 'aurons', 'celà', 'mienne', 'dessous', 'toc ', 'plein', 'miens', 'pour', 'remarquable', 'ceci', 'près', 'peut', 'pu', 'aurions', '(', 'suis', 'sujet', 'état', 'na', 'comment', 'serait', 'dix', 'p', 'dix-neuf', 'tenant', 'celle-ci', 'houp', 'étiez', 'celles', 'celles-là', 'es', 'début', 'merci', 'seriez', 'contre', 'vivat', 'ce', 'uniformement', 'voie', 'm', 'ayant', 'pense', '.', 'ouverts', 'hurrah', 'rend', 'egales', 'tel', 'ni', 'sans', 'fûtes', 'telle', 'auraient', 'anterieure', 'juste', 'nous-mêmes', 'soyons', 'BUTTON', 'o', 'seras', 'eussions', 'un', 'sont', 'jusque', 'restent', 'ça', 's', 'vous-mêmes', 'pif', 'c', 'toutefois', 'eu', 'aupres', 'las', 'superpose', 'f', 'reste', 'k', 'aurez', 'derrière', 'clac', 'être', 'depuis', 'sauf', 'hors', 'dits', 'nombreux', 'seule', 'nommés', 'valeur', 'mince', 'rares', 'parole', 'hein', 'dire', 'r', 'allons', 'tiens', 'tac', 'dans', 'quand', 'ohé', 'sur', \"quelqu'un\", 'devant', 'pfft', 'tardive', 'quatre-vingt', 'extenso', 'suffisant', 'deja', 'fûmes', 'telles', 'sera', 'devrait', 'était', 'differentes', 'rarement', 'sein', 'eh', 'quant-à-soi', 'ô', 'suivante', 'seize', 'pouvait', 'serez', 'q', 'olé', 'différentes', 'vôtre', 'tenir', \"aujourd'hui\", 'feront', 'troisième', 'lui', 'derniere', 'chez', 'ah', 'siens', 'lesquels', 'quiconque', 'strictement', 'n', 'mes', 'quoi', 'sois', 'sienne', 'siennes', 'cinquantième', 'laisser', 'étante', 'divers', '\"', 'chiche', 'serais', 'subtiles', 'concernant', 'celui-ci', 'suivre', 'tandis', 'nous', 'haut', 'cet', 'ma', 'ceux', 'flac', 'plutôt', 'pourquoi', 'peu', 'sixième', 'ouverte', 'etc', 'precisement', 'z', \"d'être\", 'hop', 'suivant', 'parle', 'w', \"n'y\", 'aurait', 'vlan', 'e', 'bien', 'dring', 'euh', 'quatrième', 'était ', 'là', 'non', 'dont', 'qui', 'elles-mêmes', 'anterieures', 'avais', 'notamment', 'tels', 'aura', 'oust', 'hélas', 'aurai', 'après', 'Swallow', 'auront', 'autre', 'encore', 'hé', 'pan', 'ainsi', 'chut', 'étions', 'premier', 'cher', 'plusieurs', 'en', 'auriez', 'mêmes', 'quelles', 'autrement', 'quatorze', 'diverse', 'neuvième', 'plupart', 'êtes', 'allo', 'multiple', 'prealable', 'excepté', 'pres', 'on', 'sapristi', 'sept', 'dos', 'deux', 'as', 'puisque', 'dix-huit', 'gens', 'de', 'v', 'fusse', 'bas', 'vingt', 'alors', 'me', 'tous', 'malgre', 'se', 'suit', 'parce', 'certains', 'jusqu', 'mille', 'vers', 'ses', 'chères', 'différente', 'plouf', 'malgré', 'dit', 'procedant', 'desquels', 'effet', 'doit', 'néanmoins', 'personne', 'moi-meme', 'onzième', 'vu', 'que', 'avons', 'tu', 'sinon', 'certaine', 'etre', 'apres', 'dixième', 'compris', 'aux', 'quel', 'voilà', 'étée', 'maximale', 'fussions', 'étés', 'mien', 'quoique', 'maint', 'fussent', '»', 'necessaire', 'tien', 'sommes', 'soyez', 'quelque', 'cinq', 'tend', 'lorsque', 'très', 'notre', 'dès', 'vos', '?', 'auras', 'cependant', 'rare', 'assez', 'avait', 'nôtre', 'tente', 'faites', 'directement', 'j', 'allô', 'exterieur', 'memes', 'relative', 'pouah', 'celui-là', 'maintenant', 'eût', 'parmi', 'vives', 'quatrièmement', 'toujours', 'deuxième', '*', 'minimale', 'quarante', 'pièce', 'vôtres', 'ouias', 'neuf', 'psitt', 'mot', 'pfut', 'quinze', 'toc', 'seraient', 'possessifs', 'hem', 'une', 'eûmes', 'particulière', 'serait ', 'pourrais', 'étant', 'eusses', 'crac', 'pas', 'particulièrement', 'celles-ci', 'autrefois', 'ai', 'avez', 'eux-mêmes', 'quatre', 'chers', 'duquel', 'sa', 'hou', 'pff', 'bigre', 'rien', 'aucun', 'allaient', 'boum', 'moi-même', 'semblaient', 'abord', 'vais', 'durant', 'lequel', 'stop', 'seul', 'serons', 'au', 'premièrement', 'auquel', 'etant', 'quelle', 'suffit', 'leur', 'avoir', 'cinquième', 'hue', 'vive', 'donc', 'entre', 'troisièmement', 'absolument', 'speculatif', 'aucuns', 'huitième', 'soixante', 'lui-meme', 'naturelles', 'proche', 'votre', 'eûtes', 'surtout', 'façon', 'aurais', 'bah', 'toutes', 'attendu', 'egalement', 'sacrebleu', 'derriere', 'possible', 'font', 'laquelle', 'bat', 'i', 'aies', '+', 'cinquante', 'différent', 'mais', 'hormis', 'multiples', 'cette', 'voire', 'lesquelles', 'chaque', 'delà', 'brrr', 'selon', 'cela', 'sous', 'exactement', 'via', 'parseme', 'comparables', 'celle', ':', 'sent', 'comme', 'les', 'deuxièmement', 'peuvent', 'unes', 'l', 'peux', 'combien', 'tienne', 'pendant', 'personnes', 'trente', 'ore', 'ont', 'differents', 'u', 'ayante', 'permet', 'fût', 'quelques', 'leurs', 'tout', 'ayantes', 'des', 'étantes', 'bon', 'le', 'trop', 'soient', 'ollé', 'desormais', 'semble', 'certain', 'étaient', 'certaines', 'revoilà', 'mine', 'furent', 'ait', 'si', 'couic', 'chacun', 'ayez', 'meme', 'â', 'soi-même', 'avec', 'eue', 'la', 'g', 'paf', 'puis', 'vé', 'holà', 'ici', 'nul', 'trois', 'elle-même', 'faisaient', 'uniques', 'ton', 'vif', 'suffisante', 'nouveaux', 'moins', 'aient', 'outre', 'lors', 'directe', 'semblent', 'étées', 'mon', 'eux', 'environ', 'te', 'nouveau', 'quelconque', 'ès', 'ne', 'étants', 'sait', 'la ', 'fut', 'h', 'd', 'avaient', 'fait', \"l' \", 'tes', 'ouf', 'celle-là', 'fais', '!', 'clic', 'pur', 'ta', 'fus', 'septième', 'suivantes', 'serions', 'auxquelles', 'lès', 'beau', 'sont ', 'douze', 'té', 'fois', 'probable', 'y', 'nombreuses', 'plus', 'hi', 'nôtres', 'semblable', 'tant', 'different', 'c ', 'neanmoins', 'o|', 'possessif', 'moyennant', 'doivent', 'ouvert', 'tsoin', 'vifs', 'ayons', 'fusses', 'toi', 'importe', 'voient', 'afin', \"'\", 'autres', 'tsouin', 'étais', 'dernier', 'comparable', 'onze', 'faisant', 'pire', 'je', 'touchant', 'dite', 'tiennes', 'quanta', 'diverses', 'ces', 'parlent', 'cinquantaine', 'debout', 'probante', 'dedans', 'de ', 'eut', 'treize', 'il', 'avions', 'du', 'da', 'vont', 'hui', 'autant', 'particulier', 'passé', 'six', 'suivants', 'revoici', 'chacune', 'ceux-ci', 'est', 'auxquels', 'son', 'beaucoup', 'différents', 'uns', 'désormais', 'ho', 'droite', 'avant', 'naturelle', 'souvent', 'basee', '«', 'essai', 'specifiques', 'pourrait', 'eusse', 'retour', 'a', 'tres', 'voici', 'elles', 'bravo', 'devra', 'celui', 'aucune', 'seront', 'hum', 'aviez', 'restrictif', 'tellement', 'b', 'aie', 'oh', 'relativement', 'Truman', 'première', 'certes', 'aujourd', 'fussiez', 'dix-sept', 'longtemps', 'vas', 'ha', 'où', 'qu', 'parfois', 'naturel', 'pure', 'x', 'autrui', 'partant', 'parler', 'vous', 'huit', 'par', '“Être', 'toute'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('french'))\n",
    "print(len(stopWords))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8108935e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "{'y', 'tendrán', 'estad', 'sintiendo', 'fuéramos', 'o', 'sentidos', 'habiendo', 'esos', 'por', 'será', 'tu', 'tenía', 'estés', 'os', 'sentido', 'tuviéramos', 'hubieran', 'de', 'tengas', 'sí', 'esta', 'esa', 'poco', 'estada', 'contra', 'tenemos', 'sin', 'qué', 'mi', 'estuvimos', 'estuvisteis', 'estoy', 'nuestra', 'suyos', 'tendremos', 'estuvieras', 'nosotras', 'tenían', 'estáis', 'cual', 'sentid', 'nos', 'tendría', 'otras', 'estén', 'tanto', 'ese', 'tengo', 'estaría', 'tenidas', 'tuya', 'habéis', 'habrían', 'has', 'hayas', 'tuvisteis', 'fuera', 'nosotros', 'antes', 'también', 'tuyos', 'seré', 'fue', 'fueras', 'habrías', 'tengáis', 'hubieses', 'como', 'tiene', 'hayáis', 'estaré', 'estuviste', 'para', 'estaremos', 'éramos', 'muy', 'sea', 'la', 'tuviera', 'mío', 'muchos', 'él', 'tuvierais', 'hubiéramos', 'vosotras', 'fueseis', 'e', 'fuerais', 'tus', 'habían', 'sois', 'hubieras', 'hubiésemos', 'otro', 'tuvimos', 'estarás', 'siente', 'tuvo', 'entre', 'tuviste', 'ya', 'ti', 'vosotros', 'mías', 'tuvieses', 'fueran', 'estábamos', 'se', 'nuestro', 'tendrá', 'yo', 'fuisteis', 'el', 'habrás', 'nada', 'lo', 'hayan', 'eras', 'tengan', 'vuestras', 'está', 'tened', 'seamos', 'estados', 'estuviesen', 'ella', 'tienes', 'estuviéramos', 'tendrás', 'tendríamos', 'habríamos', 'tuvieran', 'tenido', 'habría', 'teníais', 'tuyo', 'estuviese', 'les', 'tengamos', 'estás', 'unos', 'vuestros', 'mí', 'tuvieron', 'estabais', 'estemos', 'hubo', 'mía', 'quien', 'fueron', 'seas', 'tendréis', 'te', 'estando', 'tenga', 'estas', 'tuviese', 'seremos', 'hubisteis', 'en', 'tendré', 'una', 'habías', 'ni', 'hayamos', 'suyas', 'habíamos', 'habrán', 'míos', 'tendrías', 'hubierais', 'eres', 'sean', 'no', 'nuestras', 'uno', 'tendríais', 'me', 'estarán', 'cuando', 'son', 'más', 'suya', 'un', 'estuvieron', 'tuve', 'habido', 'estuvo', 'del', 'era', 'tienen', 'hubiera', 'sentidas', 'estaban', 'seréis', 'estadas', 'estuviésemos', 'estuvieran', 'hemos', 'estaríais', 'ha', 'sobre', 'tuviésemos', 'hubiese', 'estuviera', 'algunas', 'las', 'están', 'le', 'todos', 'habíais', 'hubiste', 'hubieseis', 'eso', 'otros', 'ellos', 'algunos', 'fuese', 'mucho', 'fui', 'habríais', 'tuvieras', 'otra', 'habré', 'porque', 'sería', 'vuestra', 'este', 'desde', 'teniendo', 'que', 'estuve', 'ante', 'durante', 'es', 'estuvieses', 'han', 'teníamos', 'tuviesen', 'estuvierais', 'tuvieseis', 'hubiesen', 'donde', 'tenidos', 'habida', 'estarías', 'habidas', 'hay', 'habidos', 'sus', 'tenías', 'estaríamos', 'estuvieseis', 'había', 'hube', 'seríais', 'tenéis', 'esas', 'a', 'los', 'serán', 'nuestros', 'tendrían', 'sentida', 'habrá', 'estaba', 'algo', 'estaréis', 'serías', 'estar', 'erais', 'haya', 'serían', 'hubimos', 'tenida', 'quienes', 'hubieron', 'estará', 'tú', 'fuiste', 'pero', 'vuestro', 'fuésemos', 'estamos', 'he', 'eran', 'estabas', 'esté', 'fuimos', 'con', 'suyo', 'su', 'estarían', 'estéis', 'fuesen', 'ellas', 'habremos', 'estos', 'fueses', 'seáis', 'habréis', 'seríamos', 'soy', 'esto', 'todo', 'somos', 'mis', 'hasta', 'tuyas', 'serás', 'al', 'estado'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('spanish'))\n",
    "print(len(stopWords))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "898669cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "# word_tokenize accepts\n",
    "# a string as an input, not a file.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "file1 = open(\"contextes-anglais.txt\")\n",
    " \n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "words = line.split()\n",
    "for r in words:\n",
    "    if not r in stop_words:\n",
    "        appendFile = open('stopang_context.txt','a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ff82f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "# word_tokenize accepts\n",
    "# a string as an input, not a file.\n",
    "stop_words = set(stopwords.words('french'))\n",
    "file1 = open(\"contextes-français.txt\")\n",
    " \n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "words = line.split()\n",
    "for r in words:\n",
    "    if not r in stop_words:\n",
    "        appendFile = open('01stop_fr_context.txt','a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf662f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "# word_tokenize accepts\n",
    "# a string as an input, not a file.\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "file1 = open(\"contextes-espagnol.txt\")\n",
    " \n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "words = line.split()\n",
    "for r in words:\n",
    "    if not r in stop_words:\n",
    "        appendFile = open('context_nltk_espa.txt','a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6da58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
